{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warning\n",
    "\n",
    "This tutorial is a work in progress, it does not cover all the functionalities yet. However, it will give you a good overview how you can generate tumor segmentations with BraTS Toolkit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# glioma segmentation with BraTS Toolkit\n",
    "\n",
    "In this Notebook, we will demonstrate how to preprocess brain MR images with the [BrainLes preprocessing package](https://github.com/BrainLesion/preprocessing/tree/main/brainles_preprocessing). Following we will generate glioma segmentations with multiple algorithms from [BraTS Toolkit](https://github.com/neuronflow/BraTS-Toolkit) and fuse them together.\n",
    "\n",
    "---\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "### Requirements\n",
    "\n",
    "This tutorial requires:\n",
    "\n",
    "- Python 3.10+ environment\n",
    "- Docker (we recommended the most recent version)\n",
    "<!-- TODO specify version -->\n",
    "\n",
    "optional (but recommended):\n",
    "\n",
    "- CUDA drivers\n",
    "- a GPU that is supported (each algorithms supports different set of GPUs)\n",
    "<!-- TODO specify -->\n",
    "\n",
    "### Setup Colab environment\n",
    "\n",
    "If you installed the packages and requirements on your own machine, you can skip this section and start from the import section. Otherwise you can follow and execute the tutorial on your browser. In order to start working on the notebook, click on the following button, this will open this page in the Colab environment and you will be able to execute the code on your own.\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/BrainLesion/tutorials/blob/main/AURORA/tutorial.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "Now that you are visualizing the notebook in Colab, run the next cell to install the packages we will use. There are few things you should follow in order to properly set the notebook up:\n",
    "\n",
    "1. Warning: This notebook was not authored by Google. Click on 'Run anyway'.\n",
    "1. When the installation commands are done, there might be \"Restart runtime\" button at the end of the output. Please, click it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation of dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: brainles_preprocessing in /home/florian/miniconda3/envs/aurora_tutorial/lib/python3.10/site-packages (0.0.25)\n",
      "Collecting brainles_preprocessing\n",
      "  Downloading brainles_preprocessing-0.0.26-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: brats_toolkit in /home/florian/miniconda3/envs/aurora_tutorial/lib/python3.10/site-packages (1.0.14)\n",
      "Requirement already satisfied: auxiliary in /home/florian/miniconda3/envs/aurora_tutorial/lib/python3.10/site-packages (0.0.40)\n",
      "Requirement already satisfied: BrainLes-HD-BET>=0.0.5 in /home/florian/miniconda3/envs/aurora_tutorial/lib/python3.10/site-packages (from brainles_preprocessing) (0.0.5)\n",
      "Requirement already satisfied: nibabel<4.0.0,>=3.2.1 in /home/florian/miniconda3/envs/aurora_tutorial/lib/python3.10/site-packages (from brainles_preprocessing) (3.2.2)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.0 in /home/florian/.local/lib/python3.10/site-packages (from brainles_preprocessing) (1.26.2)\n",
      "Requirement already satisfied: path<17.0.0,>=16.2.0 in /home/florian/miniconda3/envs/aurora_tutorial/lib/python3.10/site-packages (from brainles_preprocessing) (16.9.0)\n",
      "Requirement already satisfied: pathlib<2.0.0,>=1.0.1 in /home/florian/.local/lib/python3.10/site-packages (from brainles_preprocessing) (1.0.1)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.6.0 in /home/florian/.local/lib/python3.10/site-packages (from brainles_preprocessing) (13.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.64.1 in /home/florian/miniconda3/envs/aurora_tutorial/lib/python3.10/site-packages (from brainles_preprocessing) (4.66.1)\n",
      "Requirement already satisfied: ttictoc<0.6.0,>=0.5.6 in /home/florian/miniconda3/envs/aurora_tutorial/lib/python3.10/site-packages (from brainles_preprocessing) (0.5.6)\n",
      "Requirement already satisfied: SimpleITK<3.0.0,>=2.3.1 in /home/florian/.local/lib/python3.10/site-packages (from brats_toolkit) (2.3.1)\n",
      "Requirement already satisfied: python-engineio<4.0.0,>=3.14.2 in /home/florian/.local/lib/python3.10/site-packages (from brats_toolkit) (3.14.2)\n",
      "Requirement already satisfied: python-socketio<5.0.0,>=4.6.1 in /home/florian/.local/lib/python3.10/site-packages (from brats_toolkit) (4.6.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /home/florian/miniconda3/envs/aurora_tutorial/lib/python3.10/site-packages (from brats_toolkit) (2.31.0)\n",
      "Requirement already satisfied: pillow>=10.0.0 in /home/florian/miniconda3/envs/aurora_tutorial/lib/python3.10/site-packages (from auxiliary) (10.2.0)\n",
      "Requirement already satisfied: tifffile>=2023.8.25 in /home/florian/.local/lib/python3.10/site-packages (from auxiliary) (2023.12.9)\n",
      "Requirement already satisfied: torch>=0.4.1 in /home/florian/.local/lib/python3.10/site-packages (from BrainLes-HD-BET>=0.0.5->brainles_preprocessing) (2.1.2)\n",
      "Requirement already satisfied: scikit-image>=0.21.0 in /home/florian/.local/lib/python3.10/site-packages (from BrainLes-HD-BET>=0.0.5->brainles_preprocessing) (0.22.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /home/florian/.local/lib/python3.10/site-packages (from nibabel<4.0.0,>=3.2.1->brainles_preprocessing) (23.2)\n",
      "Requirement already satisfied: setuptools in /home/florian/miniconda3/envs/aurora_tutorial/lib/python3.10/site-packages (from nibabel<4.0.0,>=3.2.1->brainles_preprocessing) (68.2.2)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/florian/miniconda3/envs/aurora_tutorial/lib/python3.10/site-packages (from python-engineio<4.0.0,>=3.14.2->brats_toolkit) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/florian/miniconda3/envs/aurora_tutorial/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->brats_toolkit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/florian/miniconda3/envs/aurora_tutorial/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->brats_toolkit) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/florian/miniconda3/envs/aurora_tutorial/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->brats_toolkit) (2.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/florian/miniconda3/envs/aurora_tutorial/lib/python3.10/site-packages (from requests<3.0.0,>=2.24.0->brats_toolkit) (2024.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/florian/.local/lib/python3.10/site-packages (from rich<14.0.0,>=13.6.0->brainles_preprocessing) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/florian/.local/lib/python3.10/site-packages (from rich<14.0.0,>=13.6.0->brainles_preprocessing) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/florian/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.6.0->brainles_preprocessing) (0.1.2)\n",
      "Requirement already satisfied: scipy>=1.8 in /home/florian/.local/lib/python3.10/site-packages (from scikit-image>=0.21.0->BrainLes-HD-BET>=0.0.5->brainles_preprocessing) (1.11.4)\n",
      "Requirement already satisfied: networkx>=2.8 in /home/florian/.local/lib/python3.10/site-packages (from scikit-image>=0.21.0->BrainLes-HD-BET>=0.0.5->brainles_preprocessing) (3.2.1)\n",
      "Requirement already satisfied: imageio>=2.27 in /home/florian/.local/lib/python3.10/site-packages (from scikit-image>=0.21.0->BrainLes-HD-BET>=0.0.5->brainles_preprocessing) (2.33.1)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in /home/florian/.local/lib/python3.10/site-packages (from scikit-image>=0.21.0->BrainLes-HD-BET>=0.0.5->brainles_preprocessing) (0.3)\n",
      "Requirement already satisfied: filelock in /home/florian/miniconda3/envs/aurora_tutorial/lib/python3.10/site-packages (from torch>=0.4.1->BrainLes-HD-BET>=0.0.5->brainles_preprocessing) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /home/florian/.local/lib/python3.10/site-packages (from torch>=0.4.1->BrainLes-HD-BET>=0.0.5->brainles_preprocessing) (4.8.0)\n",
      "Requirement already satisfied: sympy in /home/florian/.local/lib/python3.10/site-packages (from torch>=0.4.1->BrainLes-HD-BET>=0.0.5->brainles_preprocessing) (1.12)\n",
      "Requirement already satisfied: jinja2 in /home/florian/.local/lib/python3.10/site-packages (from torch>=0.4.1->BrainLes-HD-BET>=0.0.5->brainles_preprocessing) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/florian/.local/lib/python3.10/site-packages (from torch>=0.4.1->BrainLes-HD-BET>=0.0.5->brainles_preprocessing) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/florian/.local/lib/python3.10/site-packages (from torch>=0.4.1->BrainLes-HD-BET>=0.0.5->brainles_preprocessing) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/florian/.local/lib/python3.10/site-packages (from torch>=0.4.1->BrainLes-HD-BET>=0.0.5->brainles_preprocessing) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/florian/.local/lib/python3.10/site-packages (from torch>=0.4.1->BrainLes-HD-BET>=0.0.5->brainles_preprocessing) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/florian/.local/lib/python3.10/site-packages (from torch>=0.4.1->BrainLes-HD-BET>=0.0.5->brainles_preprocessing) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/florian/.local/lib/python3.10/site-packages (from torch>=0.4.1->BrainLes-HD-BET>=0.0.5->brainles_preprocessing) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/florian/.local/lib/python3.10/site-packages (from torch>=0.4.1->BrainLes-HD-BET>=0.0.5->brainles_preprocessing) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/florian/.local/lib/python3.10/site-packages (from torch>=0.4.1->BrainLes-HD-BET>=0.0.5->brainles_preprocessing) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/florian/.local/lib/python3.10/site-packages (from torch>=0.4.1->BrainLes-HD-BET>=0.0.5->brainles_preprocessing) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/florian/.local/lib/python3.10/site-packages (from torch>=0.4.1->BrainLes-HD-BET>=0.0.5->brainles_preprocessing) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /home/florian/.local/lib/python3.10/site-packages (from torch>=0.4.1->BrainLes-HD-BET>=0.0.5->brainles_preprocessing) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/florian/.local/lib/python3.10/site-packages (from torch>=0.4.1->BrainLes-HD-BET>=0.0.5->brainles_preprocessing) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in /home/florian/.local/lib/python3.10/site-packages (from torch>=0.4.1->BrainLes-HD-BET>=0.0.5->brainles_preprocessing) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/florian/.local/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=0.4.1->BrainLes-HD-BET>=0.0.5->brainles_preprocessing) (12.3.52)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/florian/.local/lib/python3.10/site-packages (from jinja2->torch>=0.4.1->BrainLes-HD-BET>=0.0.5->brainles_preprocessing) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/florian/.local/lib/python3.10/site-packages (from sympy->torch>=0.4.1->BrainLes-HD-BET>=0.0.5->brainles_preprocessing) (1.3.0)\n",
      "Downloading brainles_preprocessing-0.0.26-py3-none-any.whl (19.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: brainles_preprocessing\n",
      "  Attempting uninstall: brainles_preprocessing\n",
      "    Found existing installation: brainles_preprocessing 0.0.25\n",
      "    Uninstalling brainles_preprocessing-0.0.25:\n",
      "      Successfully uninstalled brainles_preprocessing-0.0.25\n",
      "Successfully installed brainles_preprocessing-0.0.26\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /home/florian/miniconda3/envs/aurora_tutorial/lib/python3.10/site-packages (3.8.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/florian/miniconda3/envs/aurora_tutorial/lib/python3.10/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/florian/.local/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/florian/miniconda3/envs/aurora_tutorial/lib/python3.10/site-packages (from matplotlib) (4.48.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/florian/.local/lib/python3.10/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /home/florian/.local/lib/python3.10/site-packages (from matplotlib) (1.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/florian/.local/lib/python3.10/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /home/florian/miniconda3/envs/aurora_tutorial/lib/python3.10/site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/florian/miniconda3/envs/aurora_tutorial/lib/python3.10/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/florian/miniconda3/envs/aurora_tutorial/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/florian/miniconda3/envs/aurora_tutorial/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U brainles_preprocessing brats_toolkit auxiliary\n",
    "%pip install -U matplotlib\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running the next cell you are going to create a folder in your Google Drive. All the files for this tutorial will be uploaded to this folder. After the first execution you might receive some warning and notification, please follow these instructions:\n",
    "\n",
    "1. Permit this notebook to access your Google Drive files? Click on 'Yes', and select your account.\n",
    "   Google Drive for desktop wants to access your Google Account. Click on 'Allow'.\n",
    "1. At this point, a folder has been created and you can navigate it through the lefthand panel in Colab, you might also have received an email that informs you about the access on your Google Drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder in your Google Drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't run this cell if you already cloned the repo\n",
    "# !git clone https://github.com/BrainLesion/tutorials.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make files from the repo available in colab\n",
    "import sys\n",
    "\n",
    "COLAB_BASE_PATH = \"/content/tutorials/BraTS-Toolkit/\"\n",
    "sys.path.insert(0, COLAB_BASE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Input data\n",
    "\n",
    "TODO describe raw input data. Two exams from TCIA/TCGA with T1, T1c, T2, T2-FLAIR with skull etc.\n",
    "TODO visualize it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "BraTS challenge algorithms expect co-registered, skullstripped files in SRI-24 space, to achieve this preprocessing is required.\n",
    "Instead of using the vanilla preprocessing pipeline from BraTS Toolkit, we recommend using the new [BrainLes preprocessing package](https://github.com/BrainLesion/preprocessing/tree/main/brainles_preprocessing).\n",
    "\n",
    "<!-- For more details about preprocessing see the dedicated tutorial at TODO -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define a function that procoesses an exam.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auxiliary.normalization.percentile_normalizer import PercentileNormalizer\n",
    "from auxiliary.turbopath import turbopath\n",
    "from tqdm import tqdm\n",
    "\n",
    "from brainles_preprocessing.brain_extraction import HDBetExtractor\n",
    "from brainles_preprocessing.modality import Modality\n",
    "from brainles_preprocessing.preprocessor import Preprocessor\n",
    "from brainles_preprocessing.registration import NiftyRegRegistrator\n",
    "\n",
    "\n",
    "def preprocess_exam_in_brats_style(inputDir: str) -> None:\n",
    "    \"\"\"\n",
    "    Perform BRATS (Brain Tumor Segmentation) style preprocessing on MRI exam data.\n",
    "\n",
    "    Args:\n",
    "        inputDir (str): Path to the directory containing raw MRI files for an exam.\n",
    "\n",
    "    Raises:\n",
    "        Exception: If any error occurs during the preprocessing.\n",
    "\n",
    "    Example:\n",
    "        brat_style_preprocess_exam(\"/path/to/exam_directory\")\n",
    "\n",
    "    This function preprocesses MRI exam data following the BRATS style, which includes the following steps:\n",
    "    1. Normalization using a percentile normalizer.\n",
    "    2. Registration and correction using NiftyReg.\n",
    "    3. Brain extraction using HDBet.\n",
    "\n",
    "    The processed data is saved in a structured directory within the input directory.\n",
    "\n",
    "    Args:\n",
    "        inputDir (str): Path to the directory containing raw MRI files for an exam.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    inputDir = turbopath(inputDir)\n",
    "    print(\"*** start ***\")\n",
    "    brainles_dir = turbopath(inputDir) + \"/\" + inputDir.name + \"_brainles\"\n",
    "    norm_bet_dir = brainles_dir / \"normalized_bet\"\n",
    "    raw_bet_dir = brainles_dir / \"raw_bet\"\n",
    "\n",
    "    t1_file = inputDir.files(\"*t1.nii.gz\")\n",
    "    t1c_file = inputDir.files(\"*t1c.nii.gz\")\n",
    "    t2_file = inputDir.files(\"*t2.nii.gz\")\n",
    "    flair_file = inputDir.files(\"*fla.nii.gz\")\n",
    "\n",
    "    # we check that we have only one file of each type\n",
    "    if len(t1_file) == len(t1c_file) == len(t2_file) == len(flair_file) == 1:\n",
    "        t1File = t1_file[0]\n",
    "        t1cFile = t1c_file[0]\n",
    "        t2File = t2_file[0]\n",
    "        flaFile = flair_file[0]\n",
    "\n",
    "        # normalizer\n",
    "        percentile_normalizer = PercentileNormalizer(\n",
    "            lower_percentile=0.1,\n",
    "            upper_percentile=99.9,\n",
    "            lower_limit=0,\n",
    "            upper_limit=1,\n",
    "        )\n",
    "        # define modalities\n",
    "        center = Modality(\n",
    "            modality_name=\"t1c\",\n",
    "            input_path=t1cFile,\n",
    "            raw_bet_output_path=raw_bet_dir / inputDir.name + \"_t1c_bet.nii.gz\",\n",
    "            normalized_bet_output_path=norm_bet_dir / inputDir.name\n",
    "            + \"_t1c_bet_normalized.nii.gz\",\n",
    "            atlas_correction=True,\n",
    "            normalizer=percentile_normalizer,\n",
    "        )\n",
    "        moving_modalities = [\n",
    "            Modality(\n",
    "                modality_name=\"t1\",\n",
    "                input_path=t1File,\n",
    "                raw_bet_output_path=raw_bet_dir / inputDir.name + \"_t1_bet.nii.gz\",\n",
    "                normalized_bet_output_path=norm_bet_dir / inputDir.name\n",
    "                + \"_t1_bet_normalized.nii.gz\",\n",
    "                atlas_correction=True,\n",
    "                normalizer=percentile_normalizer,\n",
    "            ),\n",
    "            Modality(\n",
    "                modality_name=\"t2\",\n",
    "                input_path=t2File,\n",
    "                raw_bet_output_path=raw_bet_dir / inputDir.name + \"_t2_bet.nii.gz\",\n",
    "                normalized_bet_output_path=norm_bet_dir / inputDir.name\n",
    "                + \"_t2_bet_normalized.nii.gz\",\n",
    "                atlas_correction=True,\n",
    "                normalizer=percentile_normalizer,\n",
    "            ),\n",
    "            Modality(\n",
    "                modality_name=\"flair\",\n",
    "                input_path=flaFile,\n",
    "                raw_bet_output_path=raw_bet_dir / inputDir.name + \"_fla_bet.nii.gz\",\n",
    "                normalized_bet_output_path=norm_bet_dir / inputDir.name\n",
    "                + \"_fla_bet_normalized.nii.gz\",\n",
    "                atlas_correction=True,\n",
    "                normalizer=percentile_normalizer,\n",
    "            ),\n",
    "        ]\n",
    "        preprocessor = Preprocessor(\n",
    "            center_modality=center,\n",
    "            moving_modalities=moving_modalities,\n",
    "            registrator=NiftyRegRegistrator(),\n",
    "            brain_extractor=HDBetExtractor(),\n",
    "            # optional: we provide a temporary directory as a sandbox for the preprocessin\n",
    "            temp_folder=\"temporary_directory\",\n",
    "            limit_cuda_visible_devices=\"0\",\n",
    "        )\n",
    "        preprocessor.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we loop through the exams to preprocess the data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: /home/florian/flow/BrainLesion/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA\n",
      "*** start ***\n",
      "File: /home/florian/flow/BrainLesion/tutorials/BraTS-Toolkit/temporary_directory/atlas-space/atlas__t1c.nii.gz\n",
      "preprocessing...\n",
      "image shape after preprocessing:  (103, 160, 160)\n",
      "prediction (CNN id)...\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "exporting segmentation...\n",
      "current image /home/florian/flow/BrainLesion/tutorials/BraTS-Toolkit/temporary_directory/brain-extraction/atlas_bet_t1c.nii.gz\n",
      "current image /home/florian/flow/BrainLesion/tutorials/BraTS-Toolkit/temporary_directory/brain-extraction/brain_masked/brain_masked__t1.nii.gz\n",
      "current image /home/florian/flow/BrainLesion/tutorials/BraTS-Toolkit/temporary_directory/brain-extraction/brain_masked/brain_masked__t2.nii.gz\n",
      "current image /home/florian/flow/BrainLesion/tutorials/BraTS-Toolkit/temporary_directory/brain-extraction/brain_masked/brain_masked__flair.nii.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [03:51<03:51, 231.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing: /home/florian/flow/BrainLesion/tutorials/BraTS-Toolkit/data/TCGA-DU-7294\n",
      "*** start ***\n",
      "File: /home/florian/flow/BrainLesion/tutorials/BraTS-Toolkit/temporary_directory/atlas-space/atlas__t1c.nii.gz\n",
      "preprocessing...\n",
      "image shape after preprocessing:  (103, 160, 160)\n",
      "prediction (CNN id)...\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "exporting segmentation...\n",
      "current image /home/florian/flow/BrainLesion/tutorials/BraTS-Toolkit/temporary_directory/brain-extraction/atlas_bet_t1c.nii.gz\n",
      "current image /home/florian/flow/BrainLesion/tutorials/BraTS-Toolkit/temporary_directory/brain-extraction/brain_masked/brain_masked__t1.nii.gz\n",
      "current image /home/florian/flow/BrainLesion/tutorials/BraTS-Toolkit/temporary_directory/brain-extraction/brain_masked/brain_masked__t2.nii.gz\n",
      "current image /home/florian/flow/BrainLesion/tutorials/BraTS-Toolkit/temporary_directory/brain-extraction/brain_masked/brain_masked__flair.nii.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [11:31<00:00, 345.59s/it]\n"
     ]
    }
   ],
   "source": [
    "EXAMPLE_DATA_DIR = turbopath(\"data\")\n",
    "\n",
    "exams = EXAMPLE_DATA_DIR.dirs()\n",
    "\n",
    "for exam in tqdm(exams):\n",
    "    print(\"processing:\", exam)\n",
    "    preprocess_exam_in_brats_style(exam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## segmentation with BraTS Toolkit\n",
    "\n",
    "now that we have preprocessed the data we can start segmenting it with BraTS Toolkit.\n",
    "Therefore, we again define a function to segment our files:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brats_toolkit.segmentor import Segmentor\n",
    "import os\n",
    "from auxiliary.turbopath import turbopath\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def segment_exam(\n",
    "    t1_file: str,\n",
    "    t1c_file: str,\n",
    "    t2_file: str,\n",
    "    fla_file: str,\n",
    "    segmentation_file: str,\n",
    "    cid: str,\n",
    "    cuda_device=\"0\",\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    segment_exam - Segments MRI images using a specified algorithm from the BRATS toolkit.\n",
    "\n",
    "    Parameters:\n",
    "        t1_file (str): Path to the T1-weighted MRI image file.\n",
    "        t1c_file (str): Path to the T1-weighted contrast-enhanced MRI image file.\n",
    "        t2_file (str): Path to the T2-weighted MRI image file.\n",
    "        fla_file (str): Path to the Fluid-attenuated inversion recovery (FLAIR) MRI image file.\n",
    "        segmentation_file (str): Path to the output file where the segmented image will be saved.\n",
    "        cid (str): Algorithm identifier for segmentation.\n",
    "        cuda_device (str, optional): CUDA device ID for GPU acceleration. Default is \"0\".\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Example:\n",
    "        segment_exam(\n",
    "            t1_file='/path/to/t1.nii.gz',\n",
    "            t1c_file='/path/to/t1c.nii.gz',\n",
    "            t2_file='/path/to/t2.nii.gz',\n",
    "            fla_file='/path/to/fla.nii.gz',\n",
    "            segmentation_file='/path/to/segmentation_result.nii.gz',\n",
    "            cid=\"mic-dkfz\"\n",
    "        )\n",
    "\n",
    "    This function segments MRI images using the specified algorithm from the BRATS toolkit. It accepts paths to T1-weighted,\n",
    "    T1-weighted contrast-enhanced, T2-weighted, and FLAIR MRI images, and performs segmentation using the specified algorithm.\n",
    "    The segmented image is saved in the specified output file.\n",
    "\n",
    "    Note:\n",
    "        - The function uses the BRATS toolkit's Segmentor for segmentation.\n",
    "        - The 'cid' parameter specifies the algorithm to use.\n",
    "        - Segmentation results are saved with a file name corresponding to the algorithm identifier (cid).\n",
    "        - Errors during segmentation are caught, and an error message is printed.\n",
    "    \"\"\"\n",
    "\n",
    "    # instantiate\n",
    "    seg = Segmentor(\n",
    "        verbose=True,\n",
    "        gpu=cuda_device,\n",
    "    )\n",
    "\n",
    "    # algorithms we want to select for segmentation\n",
    "\n",
    "    # execute it\n",
    "    if not os.path.exists(segmentation_file):\n",
    "        seg.segment(\n",
    "            t1=t1_file,\n",
    "            t2=t2_file,\n",
    "            t1c=t1c_file,\n",
    "            fla=fla_file,\n",
    "            cid=cid,\n",
    "            outputPath=segmentation_file,\n",
    "        )\n",
    "    else:\n",
    "        print(segmentation_file, \"already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now we again loop through our exams:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exams:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segmenting: /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA with algorithm: isen-20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────── </span>Thank you for using <span style=\"font-weight: bold\">BraTS Toolkit</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────────────────── \u001b[0mThank you for using \u001b[1mBraTS Toolkit\u001b[0m\u001b[92m ────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Please support our development by citing BraTS Toolkit and the papers of the segmentation algorithms you use:   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Please support our development by citing BraTS Toolkit and the papers of the segmentation algorithms you use:   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                        <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://github.com/neuronflow/BraTS-Toolkit#citation</span> -- Thank you!                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                        \u001b[4;94mhttps://github.com/neuronflow/BraTS-Toolkit#citation\u001b[0m -- Thank you!                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/segmentation/isen-20.nii.gz already exists\n",
      "segmenting: /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA with algorithm: hnfnetv1-20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────── </span>Thank you for using <span style=\"font-weight: bold\">BraTS Toolkit</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────────────────── \u001b[0mThank you for using \u001b[1mBraTS Toolkit\u001b[0m\u001b[92m ────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Please support our development by citing BraTS Toolkit and the papers of the segmentation algorithms you use:   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Please support our development by citing BraTS Toolkit and the papers of the segmentation algorithms you use:   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                        <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://github.com/neuronflow/BraTS-Toolkit#citation</span> -- Thank you!                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                        \u001b[4;94mhttps://github.com/neuronflow/BraTS-Toolkit#citation\u001b[0m -- Thank you!                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/segmentation/hnfnetv1-20.nii.gz already exists\n",
      "segmenting: /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA with algorithm: yixinmpl-20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────── </span>Thank you for using <span style=\"font-weight: bold\">BraTS Toolkit</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────────────────── \u001b[0mThank you for using \u001b[1mBraTS Toolkit\u001b[0m\u001b[92m ────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Please support our development by citing BraTS Toolkit and the papers of the segmentation algorithms you use:   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Please support our development by citing BraTS Toolkit and the papers of the segmentation algorithms you use:   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                        <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://github.com/neuronflow/BraTS-Toolkit#citation</span> -- Thank you!                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                        \u001b[4;94mhttps://github.com/neuronflow/BraTS-Toolkit#citation\u001b[0m -- Thank you!                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/segmentation/yixinmpl-20.nii.gz already exists\n",
      "segmenting: /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA with algorithm: sanet0-20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────── </span>Thank you for using <span style=\"font-weight: bold\">BraTS Toolkit</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────────────────── \u001b[0mThank you for using \u001b[1mBraTS Toolkit\u001b[0m\u001b[92m ────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Please support our development by citing BraTS Toolkit and the papers of the segmentation algorithms you use:   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Please support our development by citing BraTS Toolkit and the papers of the segmentation algorithms you use:   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                        <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://github.com/neuronflow/BraTS-Toolkit#citation</span> -- Thank you!                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                        \u001b[4;94mhttps://github.com/neuronflow/BraTS-Toolkit#citation\u001b[0m -- Thank you!                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/segmentation/sanet0-20.nii.gz already exists\n",
      "segmenting: /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA with algorithm: scan-20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────── </span>Thank you for using <span style=\"font-weight: bold\">BraTS Toolkit</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────────────────── \u001b[0mThank you for using \u001b[1mBraTS Toolkit\u001b[0m\u001b[92m ────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Please support our development by citing BraTS Toolkit and the papers of the segmentation algorithms you use:   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Please support our development by citing BraTS Toolkit and the papers of the segmentation algorithms you use:   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                        <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://github.com/neuronflow/BraTS-Toolkit#citation</span> -- Thank you!                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                        \u001b[4;94mhttps://github.com/neuronflow/BraTS-Toolkit#citation\u001b[0m -- Thank you!                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/segmentation/scan-20.nii.gz already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segmenting: /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294 with algorithm: isen-20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────── </span>Thank you for using <span style=\"font-weight: bold\">BraTS Toolkit</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────────────────── \u001b[0mThank you for using \u001b[1mBraTS Toolkit\u001b[0m\u001b[92m ────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Please support our development by citing BraTS Toolkit and the papers of the segmentation algorithms you use:   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Please support our development by citing BraTS Toolkit and the papers of the segmentation algorithms you use:   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                        <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://github.com/neuronflow/BraTS-Toolkit#citation</span> -- Thank you!                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                        \u001b[4;94mhttps://github.com/neuronflow/BraTS-Toolkit#citation\u001b[0m -- Thank you!                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/segmentation/isen-20.nii.gz already exists\n",
      "segmenting: /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294 with algorithm: hnfnetv1-20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────── </span>Thank you for using <span style=\"font-weight: bold\">BraTS Toolkit</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────────────────── \u001b[0mThank you for using \u001b[1mBraTS Toolkit\u001b[0m\u001b[92m ────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Please support our development by citing BraTS Toolkit and the papers of the segmentation algorithms you use:   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Please support our development by citing BraTS Toolkit and the papers of the segmentation algorithms you use:   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                        <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://github.com/neuronflow/BraTS-Toolkit#citation</span> -- Thank you!                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                        \u001b[4;94mhttps://github.com/neuronflow/BraTS-Toolkit#citation\u001b[0m -- Thank you!                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/segmentation/hnfnetv1-20.nii.gz already exists\n",
      "segmenting: /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294 with algorithm: yixinmpl-20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────── </span>Thank you for using <span style=\"font-weight: bold\">BraTS Toolkit</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────────────────── \u001b[0mThank you for using \u001b[1mBraTS Toolkit\u001b[0m\u001b[92m ────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Please support our development by citing BraTS Toolkit and the papers of the segmentation algorithms you use:   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Please support our development by citing BraTS Toolkit and the papers of the segmentation algorithms you use:   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                        <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://github.com/neuronflow/BraTS-Toolkit#citation</span> -- Thank you!                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                        \u001b[4;94mhttps://github.com/neuronflow/BraTS-Toolkit#citation\u001b[0m -- Thank you!                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/segmentation/yixinmpl-20.nii.gz already exists\n",
      "segmenting: /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294 with algorithm: sanet0-20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────── </span>Thank you for using <span style=\"font-weight: bold\">BraTS Toolkit</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────────────────── \u001b[0mThank you for using \u001b[1mBraTS Toolkit\u001b[0m\u001b[92m ────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Please support our development by citing BraTS Toolkit and the papers of the segmentation algorithms you use:   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Please support our development by citing BraTS Toolkit and the papers of the segmentation algorithms you use:   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                        <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://github.com/neuronflow/BraTS-Toolkit#citation</span> -- Thank you!                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                        \u001b[4;94mhttps://github.com/neuronflow/BraTS-Toolkit#citation\u001b[0m -- Thank you!                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/segmentation/sanet0-20.nii.gz already exists\n",
      "segmenting: /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294 with algorithm: scan-20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────── </span>Thank you for using <span style=\"font-weight: bold\">BraTS Toolkit</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────────────────── \u001b[0mThank you for using \u001b[1mBraTS Toolkit\u001b[0m\u001b[92m ────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Please support our development by citing BraTS Toolkit and the papers of the segmentation algorithms you use:   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Please support our development by citing BraTS Toolkit and the papers of the segmentation algorithms you use:   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                        <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://github.com/neuronflow/BraTS-Toolkit#citation</span> -- Thank you!                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                        \u001b[4;94mhttps://github.com/neuronflow/BraTS-Toolkit#citation\u001b[0m -- Thank you!                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exams: 100%|██████████| 2/2 [00:00<00:00, 11.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/segmentation/scan-20.nii.gz already exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EXAMPLE_DATA_DIR = turbopath(\"data\")\n",
    "\n",
    "exams = EXAMPLE_DATA_DIR.dirs()\n",
    "# we use these five algorithms to segment the images\n",
    "# 2019 algorithms\n",
    "# cids = [\"mic-dkfz\", \"scan\", \"xfeng\", \"lfb_rwth\", \"zyx_2019\", \"scan_2019\"]\n",
    "\n",
    "# 2020 algorithms\n",
    "cids = [\"isen-20\", \"hnfnetv1-20\", \"yixinmpl-20\", \"sanet0-20\", \"scan-20\"]\n",
    "\n",
    "\n",
    "for exam in tqdm(exams, desc=\"Exams\"):\n",
    "    for cid in tqdm(cids, desc=\"Algorithms\", leave=False):\n",
    "        print(\"segmenting:\", exam, \"with algorithm:\", cid)\n",
    "        brainles_folder = exam / exam.name + \"_brainles\"\n",
    "        preprocessed_folder = brainles_folder / \"raw_bet\"\n",
    "        segmentation_folder = brainles_folder / \"segmentation\"\n",
    "\n",
    "        segmentation_file = segmentation_folder / cid + \".nii.gz\"\n",
    "\n",
    "        segment_exam(\n",
    "            t1_file=preprocessed_folder / exam.name + \"_t1_bet.nii.gz\",\n",
    "            t1c_file=preprocessed_folder / exam.name + \"_t1c_bet.nii.gz\",\n",
    "            t2_file=preprocessed_folder / exam.name + \"_t2_bet.nii.gz\",\n",
    "            fla_file=preprocessed_folder / exam.name + \"_fla_bet.nii.gz\",\n",
    "            segmentation_file=segmentation_file,\n",
    "            cid=cid,\n",
    "            cuda_device=\"1\",\n",
    "        ),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fusion\n",
    "\n",
    "Now we can fuse the generated segmentations together. Therefore we again define a function to process our exams:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brats_toolkit.fusionator import Fusionator\n",
    "\n",
    "\n",
    "def fuse_segmentation_exam(\n",
    "    segmentation_folder: str,\n",
    "    fusion_folder: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    Fuse multiple segmentations using different methods and save the results.\n",
    "\n",
    "    Parameters:\n",
    "    - segmentation_folder (str): Path to the folder containing segmentation files in NIfTI format (*.nii.gz).\n",
    "    - fusion_folder (str): Path to the folder where fused segmentation results will be saved.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    Example:\n",
    "    ```python\n",
    "    fuse_segmentation_exam(\"/path/to/segmentations\", \"/path/to/fusion_results\")\n",
    "    ```\n",
    "\n",
    "    This function uses the Fusionator class from the brats_toolkit to fuse segmentations using two different methods:\n",
    "    1. Multimodal Average (MAV) method.\n",
    "    2. Simple fusion method.\n",
    "\n",
    "    The fused segmentations are saved in the specified `fusion_folder` with file names \"mav.nii.gz\" and \"simple.nii.gz\".\n",
    "\n",
    "    Note:\n",
    "    - The Fusionator class must be available and correctly imported from the brats_toolkit.\n",
    "    - The segmentation files in the `segmentation_folder` should be in NIfTI format (*.nii.gz).\n",
    "\n",
    "    Args:\n",
    "    - segmentation_folder (str): Path to the folder containing segmentation files in NIfTI format (*.nii.gz).\n",
    "    - fusion_folder (str): Path to the folder where fused segmentation results will be saved.\n",
    "    \"\"\"\n",
    "    # instantiate\n",
    "    fus = Fusionator(verbose=True)\n",
    "\n",
    "    # segmentation file paths\n",
    "    segmentations = segmentation_folder.files(\"*.nii.gz\")\n",
    "\n",
    "    # execution\n",
    "    # mav\n",
    "    mavPath = fusion_folder / \"mav.nii.gz\"\n",
    "    fus.fuse(\n",
    "        segmentations=segmentations,\n",
    "        outputPath=mavPath,\n",
    "        method=\"mav\",\n",
    "        weights=None,\n",
    "    )\n",
    "\n",
    "    # simple\n",
    "    simplePath = fusion_folder / \"simple.nii.gz\"\n",
    "    fus.fuse(\n",
    "        segmentations=segmentations,\n",
    "        outputPath=simplePath,\n",
    "        method=\"simple\",\n",
    "        weights=None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can again loop through our exams:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segmenting: /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────── </span>Thank you for using <span style=\"font-weight: bold\">BraTS Toolkit</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────────────────── \u001b[0mThank you for using \u001b[1mBraTS Toolkit\u001b[0m\u001b[92m ────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Please support our development by citing BraTS Toolkit and the papers of the segmentation algorithms you use:   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Please support our development by citing BraTS Toolkit and the papers of the segmentation algorithms you use:   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                        <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://github.com/neuronflow/BraTS-Toolkit#citation</span> -- Thank you!                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                        \u001b[4;94mhttps://github.com/neuronflow/BraTS-Toolkit#citation\u001b[0m -- Thank you!                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/segmentation/hnfnetv1-20.nii.gz\n",
      "Loaded: /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/segmentation/yixinmpl-20.nii.gz\n",
      "Loaded: /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/segmentation/isen-20.nii.gz\n",
      "Loaded: /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/segmentation/sanet0-20.nii.gz\n",
      "Loaded: /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/segmentation/scan-20.nii.gz\n",
      "Orchestra: Now fusing all passed .nii.gz files using MAJORITY VOTING. For more output, set the -v or --verbose flag or instantiate the fusionator class with verbose=true\n",
      "Number of segmentations to be fused using compound majority vote is:  5\n",
      "Labels of current candidate: [0 1 2 4], dtype: uint8\n",
      "Labels of current candidate: [0 1 2 4], dtype: uint8\n",
      "Labels of current candidate: [0 1 2 4], dtype: uint8\n",
      "Labels of current candidate: [0 1 2 4], dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels of current candidate: [0 1 2 4], dtype: uint8\n",
      "Labels: [1 2 4]\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "5\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "5\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "5\n",
      "Shape of result: (155, 240, 240)\n",
      "Labels and datatype of result: 4.0 0.0 float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/mav.nii.gz.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting float64 to uint8 np.ndarray\n",
      "Loaded: /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/segmentation/hnfnetv1-20.nii.gz\n",
      "Loaded: /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/segmentation/yixinmpl-20.nii.gz\n",
      "Loaded: /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/segmentation/isen-20.nii.gz\n",
      "Loaded: /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/segmentation/sanet0-20.nii.gz\n",
      "Loaded: /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/segmentation/scan-20.nii.gz\n",
      "Orchestra: Now fusing all passed .nii.gz files in using SIMPLE. For more output, set the -v or --verbose flag or instantiate the fusionator class with verbose=true\n",
      "Number of segmentations to be fused using SIMPLE is:  5\n",
      "Labels of current candidate: [0 1 2 4], dtype: uint8\n",
      "Labels of current candidate: [0 1 2 4], dtype: uint8\n",
      "Labels of current candidate: [0 1 2 4], dtype: uint8\n",
      "Labels of current candidate: [0 1 2 4], dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels of current candidate: [0 1 2 4], dtype: uint8\n",
      "Currently fusing label 1\n",
      "(155, 240, 240)\n",
      "Number of segmentations to be fused using compound majority vote is:  5\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 3410\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 1886\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 2155\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 3005\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 2867\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "Shape of result: (155, 240, 240)\n",
      "Shape of current input array: (155, 240, 240)\n",
      "Labels and datatype of current output: 1.0 0.0 float64\n",
      "Number of segmentations to be fused using compound majority vote is:  5\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 3410\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 1886\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 2155\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 3005\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 2867\n",
      "weight is: 3.258616779885049\n",
      "weight is: 3.1511742446548916\n",
      "weight is: 3.343718586032138\n",
      "weight is: 3.5990560996214467\n",
      "weight is: 3.0533377014683207\n",
      "Shape of result: (155, 240, 240)\n",
      "Shape of current input array: (155, 240, 240)\n",
      "Labels and datatype of current output: 1.0 0.0 float64\n",
      "Convergence for label 1 after 0 iterations reached.\n",
      "Currently fusing label 2\n",
      "(155, 240, 240)\n",
      "Number of segmentations to be fused using compound majority vote is:  5\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 19746\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 24365\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 26045\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 19935\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 16958\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "Shape of result: (155, 240, 240)\n",
      "Shape of current input array: (155, 240, 240)\n",
      "Labels and datatype of current output: 1.0 0.0 float64\n",
      "Number of segmentations to be fused using compound majority vote is:  5\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 19746\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 24365\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 26045\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 19935\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 16958\n",
      "weight is: 3.806188837471846\n",
      "weight is: 3.6451807045381535\n",
      "weight is: 3.5102207691555116\n",
      "weight is: 3.861889228137042\n",
      "weight is: 3.4225978325341364\n",
      "Shape of result: (155, 240, 240)\n",
      "Shape of current input array: (155, 240, 240)\n",
      "Labels and datatype of current output: 1.0 0.0 float64\n",
      "Convergence for label 2 after 0 iterations reached.\n",
      "Currently fusing label 4\n",
      "(155, 240, 240)\n",
      "Number of segmentations to be fused using compound majority vote is:  5\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 6569\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 7628\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 7605\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 6808\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 5909\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "Shape of result: (155, 240, 240)\n",
      "Shape of current input array: (155, 240, 240)\n",
      "Labels and datatype of current output: 1.0 0.0 float64\n",
      "Number of segmentations to be fused using compound majority vote is:  5\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 6569\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 7628\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 7605\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 6808\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 5909\n",
      "weight is: 3.895390628501695\n",
      "weight is: 3.776505044184724\n",
      "weight is: 3.7866546517920887\n",
      "weight is: 3.9573242849181356\n",
      "weight is: 3.7132313583169902\n",
      "Shape of result: (155, 240, 240)\n",
      "Shape of current input array: (155, 240, 240)\n",
      "Labels and datatype of current output: 1.0 0.0 float64\n",
      "Convergence for label 4 after 0 iterations reached.\n",
      "Shape of result: (155, 240, 240)\n",
      "Shape of current input array: (155, 240, 240)\n",
      "Labels and datatype of current output: 4.0 0.0 float64\n",
      "Converting float64 to uint8 np.ndarray\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/OtherEXampleFromTCIA/OtherEXampleFromTCIA_brainles/fusion/simple.nii.gz.\n",
      " 50%|█████     | 1/2 [00:20<00:20, 20.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "segmenting: /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">──────────────────────────────────────── </span>Thank you for using <span style=\"font-weight: bold\">BraTS Toolkit</span><span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m──────────────────────────────────────── \u001b[0mThank you for using \u001b[1mBraTS Toolkit\u001b[0m\u001b[92m ────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">   Please support our development by citing BraTS Toolkit and the papers of the segmentation algorithms you use:   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "   Please support our development by citing BraTS Toolkit and the papers of the segmentation algorithms you use:   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                        <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://github.com/neuronflow/BraTS-Toolkit#citation</span> -- Thank you!                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                        \u001b[4;94mhttps://github.com/neuronflow/BraTS-Toolkit#citation\u001b[0m -- Thank you!                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/segmentation/hnfnetv1-20.nii.gz\n",
      "Loaded: /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/segmentation/yixinmpl-20.nii.gz\n",
      "Loaded: /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/segmentation/isen-20.nii.gz\n",
      "Loaded: /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/segmentation/sanet0-20.nii.gz\n",
      "Loaded: /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/segmentation/scan-20.nii.gz\n",
      "Orchestra: Now fusing all passed .nii.gz files using MAJORITY VOTING. For more output, set the -v or --verbose flag or instantiate the fusionator class with verbose=true\n",
      "Number of segmentations to be fused using compound majority vote is:  5\n",
      "Labels of current candidate: [0 1 2 4], dtype: uint8\n",
      "Labels of current candidate: [0 1 2], dtype: uint8\n",
      "Labels of current candidate: [0 1 2], dtype: uint8\n",
      "Labels of current candidate: [0 1 2 4], dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels of current candidate: [0 1 2], dtype: uint8\n",
      "Labels: [1 2 4]\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "5\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "5\n",
      "weight is: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/mav.nii.gz.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "5\n",
      "Shape of result: (155, 240, 240)\n",
      "Labels and datatype of result: 2.0 0.0 float64\n",
      "Converting float64 to uint8 np.ndarray\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/mav.nii.gz.\n",
      "Segmentation Fusion with method mav saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/mav.nii.gz.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/segmentation/hnfnetv1-20.nii.gz\n",
      "Loaded: /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/segmentation/yixinmpl-20.nii.gz\n",
      "Loaded: /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/segmentation/isen-20.nii.gz\n",
      "Loaded: /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/segmentation/sanet0-20.nii.gz\n",
      "Loaded: /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/segmentation/scan-20.nii.gz\n",
      "Orchestra: Now fusing all passed .nii.gz files in using SIMPLE. For more output, set the -v or --verbose flag or instantiate the fusionator class with verbose=true\n",
      "Number of segmentations to be fused using SIMPLE is:  5\n",
      "Labels of current candidate: [0 1 2 4], dtype: uint8\n",
      "Labels of current candidate: [0 1 2], dtype: uint8\n",
      "Labels of current candidate: [0 1 2], dtype: uint8\n",
      "Labels of current candidate: [0 1 2 4], dtype: uint8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "No labels passed, choosing those labels automatically: [0 1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n",
      "Fusing a segmentation with the labels: [1 2 4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels of current candidate: [0 1 2], dtype: uint8\n",
      "Currently fusing label 1\n",
      "(155, 240, 240)\n",
      "Number of segmentations to be fused using compound majority vote is:  5\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 10541\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 9122\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 9180\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 9608\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 9115\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "Shape of result: (155, 240, 240)\n",
      "Shape of current input array: (155, 240, 240)\n",
      "Labels and datatype of current output: 1.0 0.0 float64\n",
      "Number of segmentations to be fused using compound majority vote is:  5\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 10541\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 9122\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 9180\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 9608\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 9115\n",
      "weight is: 3.637696953801965\n",
      "weight is: 3.740271506862001\n",
      "weight is: 3.8240892486370663\n",
      "weight is: 3.8234751640007185\n",
      "weight is: 3.69218021577528\n",
      "Shape of result: (155, 240, 240)\n",
      "Shape of current input array: (155, 240, 240)\n",
      "Labels and datatype of current output: 1.0 0.0 float64\n",
      "Convergence for label 1 after 0 iterations reached.\n",
      "Currently fusing label 2\n",
      "(155, 240, 240)\n",
      "Number of segmentations to be fused using compound majority vote is:  5\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 14450\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 14547\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 14527\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 14593\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 15764\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "Shape of result: (155, 240, 240)\n",
      "Shape of current input array: (155, 240, 240)\n",
      "Labels and datatype of current output: 1.0 0.0 float64\n",
      "Number of segmentations to be fused using compound majority vote is:  5\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 14450\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 14547\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 14527\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 14593\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 15764\n",
      "weight is: 3.6542352407582173\n",
      "weight is: 3.752705851139802\n",
      "weight is: 3.7886928242593774\n",
      "weight is: 3.849843061189314\n",
      "weight is: 3.7032811775246737\n",
      "Shape of result: (155, 240, 240)\n",
      "Shape of current input array: (155, 240, 240)\n",
      "Labels and datatype of current output: 1.0 0.0 float64\n",
      "Convergence for label 2 after 0 iterations reached.\n",
      "Currently fusing label 4\n",
      "(155, 240, 240)\n",
      "Number of segmentations to be fused using compound majority vote is:  5\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 352\n",
      "Candidate with shape (155, 240, 240) and values [0] and sum 0\n",
      "Candidate with shape (155, 240, 240) and values [0] and sum 0\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate with shape (155, 240, 240) and values [0] and sum 0\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "Majority Voting in SIMPLE returned an empty array\n",
      "Majority Voting in SIMPLE returned an empty array\n",
      "Majority Voting in SIMPLE returned an empty array\n",
      "Majority Voting in SIMPLE returned an empty array\n",
      "Majority Voting in SIMPLE returned an empty array\n",
      "Majority Voting in SIMPLE returned an empty array\n",
      "Majority Voting in SIMPLE returned an empty array\n",
      "Majority Voting in SIMPLE returned an empty array\n",
      "Majority Voting in SIMPLE returned an empty array\n",
      "Majority Voting in SIMPLE returned an empty array\n",
      "Majority Voting in SIMPLE returned an empty array\n",
      "Majority Voting in SIMPLE returned an empty array\n",
      "Majority Voting in SIMPLE returned an empty array\n",
      "Majority Voting in SIMPLE returned an empty array\n",
      "Majority Voting in SIMPLE returned an empty array\n",
      "Majority Voting in SIMPLE returned an empty array\n",
      "Majority Voting in SIMPLE returned an empty array\n",
      "Majority Voting in SIMPLE returned an empty array\n",
      "Majority Voting in SIMPLE returned an empty array\n",
      "Majority Voting in SIMPLE returned an empty array\n",
      "Majority Voting in SIMPLE returned an empty array\n",
      "Majority Voting in SIMPLE returned an empty array\n",
      "Majority Voting in SIMPLE returned an empty array\n",
      "Majority Voting in SIMPLE returned an empty array\n",
      "Majority Voting in SIMPLE returned an empty array\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight is: 1\n",
      "Shape of result: (155, 240, 240)\n",
      "Shape of current input array: (155, 240, 240)\n",
      "Labels and datatype of current output: 0.0 0.0 float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/koflerf/miniconda3/envs/brainles_tutorials/lib/python3.10/site-packages/brats_toolkit/fusionator.py:556: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  FNR = FN / (FN + TP)\n",
      "/home/koflerf/miniconda3/envs/brainles_tutorials/lib/python3.10/site-packages/brats_toolkit/fusionator.py:557: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  TPR = TP / (TP + FN)\n",
      "/home/koflerf/miniconda3/envs/brainles_tutorials/lib/python3.10/site-packages/brats_toolkit/fusionator.py:565: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  score = 2 * TP / (2 * TP + FP + FN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of segmentations to be fused using compound majority vote is:  5\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 352\n",
      "Candidate with shape (155, 240, 240) and values [0] and sum 0\n",
      "Candidate with shape (155, 240, 240) and values [0] and sum 0\n",
      "Candidate with shape (155, 240, 240) and values [0 1] and sum 279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate with shape (155, 240, 240) and values [0] and sum 0\n",
      "weight is: 1.0\n",
      "weight is: 1\n",
      "weight is: 1\n",
      "weight is: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n",
      "The passed segmentation contains labels other than 1 and 0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight is: 1\n",
      "Shape of result: (155, 240, 240)\n",
      "Shape of current input array: (155, 240, 240)\n",
      "Labels and datatype of current output: 0.0 0.0 float64\n",
      "Convergence for label 4 after 0 iterations reached.\n",
      "Shape of result: (155, 240, 240)\n",
      "Shape of current input array: (155, 240, 240)\n",
      "Labels and datatype of current output: 2.0 0.0 float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/simple.nii.gz.\n",
      "Segmentation Fusion with method simple saved as /home/koflerf/tutorials/BraTS-Toolkit/data/TCGA-DU-7294/TCGA-DU-7294_brainles/fusion/simple.nii.gz.\n",
      "100%|██████████| 2/2 [00:40<00:00, 20.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting float64 to uint8 np.ndarray\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EXAMPLE_DATA_DIR = turbopath(\"data\")\n",
    "\n",
    "exams = EXAMPLE_DATA_DIR.dirs()\n",
    "\n",
    "for exam in tqdm(exams):\n",
    "    print(\"segmenting:\", exam)\n",
    "    brainles_folder = exam / exam.name + \"_brainles\"\n",
    "    segmentation_folder = brainles_folder / \"segmentation\"\n",
    "    fusion_folder = brainles_folder / \"fusion\"\n",
    "\n",
    "    fuse_segmentation_exam(\n",
    "        segmentation_folder=segmentation_folder,\n",
    "        fusion_folder=fusion_folder,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Viz TODO add such visualizations## Data\n",
    "\n",
    "AURORA expects _preprocessed_ input data as NIfTI file or NumPy Array (_preprocessed_ meaning the files should be co-registerend, skullstripped and in SRI-24 space).\n",
    "\n",
    "In this example we provide sample data from the [ASNR-MICCAI BraTS Brain Metastasis Challenge](https://www.synapse.org/#!Synapse:syn51156910/wiki/622553), which is already preprocessed in the `AURORA/data` folder in the form of 4 modalities of the same brain (T1, T1C, T2, FLAIR). To get an intuition of the data, one example slice of the 3D scans is visualized below.\n",
    "\n",
    "For your own data:\n",
    "If the data is _not_ preprocessed yet, consider using our [BrainLes preprocessing](https://github.com/BrainLesion/preprocessing) package (or its predecessor [BraTS-Toolkit](https://github.com/neuronflow/BraTS-Toolkit)). -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.visualize_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Visualize results -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.visualize_segmentation(\n",
    "#     modality_file=\"data/t1c.nii.gz\",\n",
    "#     segmentation_file=\"output/t1c_segmentation.nii.gz\",\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
