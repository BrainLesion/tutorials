{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Case: Unmatched Instances Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from auxiliary.nifti.io import read_nifti\n",
    "from panoptica import (NaiveOneToOneMatching, Panoptic_Evaluator, UnmatchedInstancePair)\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Example Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate we use a reference and predicition of spine a segmentation with matched instances.\n",
    "\n",
    "\n",
    "<img src=\"./spine_seg/unmatched_instance/fig.png\" alt=\"unmatched_instance_figure\" height=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   2,   3,   4,   5,   6,   7,   8,  26, 102, 103, 104, 105,\n",
       "        106, 107, 108, 202, 203, 204, 205, 206, 207, 208], dtype=uint8),\n",
       " array([  0,   3,   4,   5,   6,   7,   8,   9,  27, 103, 104, 105, 106,\n",
       "        107, 108, 109, 203, 204, 205, 206, 207, 208, 209], dtype=uint8))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_masks = read_nifti(\n",
    "    \"./spine_seg/unmatched_instance/ref.nii.gz\"\n",
    ")\n",
    "pred_masks = read_nifti(\n",
    "    \"./spine_seg/unmatched_instance/pred.nii.gz\"\n",
    ")\n",
    "\n",
    "# labels are unmatching\n",
    "np.unique(ref_masks), np.unique(pred_masks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluate took 1.2913908958435059 seconds to execute.\n",
      "Number of instances in prediction: 22\n",
      "Number of instances in reference: 22\n",
      "True Positives (tp): 19\n",
      "False Positives (fp): 3\n",
      "False Negatives (fn): 3\n",
      "Recognition Quality / F1 Score (RQ): 0.8636363636363636\n",
      "Segmentation Quality (SQ): 0.8328184295330797 ± 0.1518606400451747\n",
      "Panoptic Quality (PQ): 0.7192522800512962\n",
      "volumetric instance-wise DICE: 0.900292616009954 ± 0.10253566174957332\n"
     ]
    }
   ],
   "source": [
    "sample = UnmatchedInstancePair(pred_masks, ref_masks)\n",
    "evaluator = Panoptic_Evaluator(\n",
    "    expected_input=UnmatchedInstancePair,\n",
    "    instance_matcher=NaiveOneToOneMatching(),\n",
    "    iou_threshold=0.5,\n",
    ")\n",
    "\n",
    "result, debug_data = evaluator.evaluate(sample)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainles",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
