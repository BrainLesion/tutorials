{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BraTS \n",
    "In this Notebook we will demonstrate how to use the BraTS package to use top performing algorithms from the BraTS challenges.\n",
    "\n",
    "---\n",
    "## Getting Started\n",
    "\n",
    "#### This tutorial requires:\n",
    "\n",
    "   - Python 3.8+\n",
    "   - Docker: Installation instructions on the official [website](https://docs.docker.com/get-docker/)\n",
    "\n",
    "\n",
    "#### Optional but recommended:\n",
    "   <!--CUDA 11.4+ (https://developer.nvidia.com/cuda-toolkit)-->\n",
    "   - GPU with CUDA support (*otherwise CPU can be used for a some algorithms*) \n",
    "   - NVIDIA Container Toolkit: Refer to the [NVIDIA install guide](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html) and the official [GitHub page](https://github.com/NVIDIA/nvidia-container-toolkit) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Installations\n",
    "!pip install brats matplotlib ipywidgets > /dev/null\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you installed the packages and requirements on your own machine, you can skip this section and start from the import section.\n",
    "\n",
    "### Setup Colab environment (optional) \n",
    "Otherwise you can follow and execute the tutorial on your browser.\n",
    "In order to start working on the notebook, click on the following button, this will open this page in the Colab environment and you will be able to execute the code on your own (*Google account required*).\n",
    "\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/BrainLesion/tutorials/blob/main/BraTS/tutorial.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>\n",
    "\n",
    "Now that you are visualizing the notebook in Colab, run the next cell to install the packages we will use. There are few things you should follow in order to properly set the notebook up:\n",
    "1. Warning: This notebook was not authored by Google. Click on 'Run anyway'.\n",
    "1. When the installation commands are done, there might be \"Restart runtime\" button at the end of the output. Please, click it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run the next cell in a Google Colab environment, it will **clone the 'tutorials' repository** in your google drive. This will create a **new folder** called \"tutorials\" in **your Google Drive**.\n",
    "All generated file will be created/uploaded to your Google Drive respectively.\n",
    "\n",
    "After the first execution of the next cell, you might receive some warnings and notifications, please follow these instructions:\n",
    "   - 'Permit this notebook to access your Google Drive files?' Click on 'Yes', and select your account.\n",
    "   - Google Drive for desktop wants to access your Google Account. Click on 'Allow'.\n",
    "\n",
    "Afterwards the \"tutorials\" folder has been created. You can navigate it through the lefthand panel in Colab. You might also have received an email that informs you about the access on your Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Check if we are in google colab currently\n",
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    colabFlag = True\n",
    "except ImportError as r:\n",
    "    colabFlag = False\n",
    "\n",
    "# Execute certain steps only if we are in a colab environment\n",
    "if colabFlag:\n",
    "    # Create a folder in your Google Drive\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/drive\")\n",
    "    # clone repository and set path\n",
    "    !git clone https://github.com/BrainLesion/tutorials.git /content/drive/MyDrive/tutorials\n",
    "    BASE_PATH = \"/content/drive/MyDrive/tutorials/BraTS/\"\n",
    "    sys.path.insert(0, BASE_PATH)\n",
    "\n",
    "else:  # normal jupyter notebook environment\n",
    "    BASE_PATH = \"./\"  # current working directory would be BraTs-Toolkit anyways if you are not in colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from brats import AdultGliomaSegmenter\n",
    "from brats.constants import AdultGliomaAlgorithms\n",
    "import utils  # local file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "AURORA expects *preprocessed* input data as NIfTI file or NumPy Array (*preprocessed* meaning the files should be co-registerend, skullstripped and in SRI-24 space).\n",
    "\n",
    "In this example we provide sample data from the [ASNR-MICCAI BraTS Brain Metastasis Challenge](https://www.synapse.org/#!Synapse:syn51156910/wiki/622553), which is already preprocessed in the `AURORA/data` folder in the form of 4 modalities of the same brain (T1, T1C, T2, FLAIR). To get an intuition of the data, one example slice of the 3D scans is visualized below.\n",
    "\n",
    "For your own data:\n",
    "If the data is *not* preprocessed yet, consider using our [BrainLes preprocessing](https://github.com/BrainLesion/preprocessing) package (or its predecessor [BraTS-Toolkit](https://github.com/neuronflow/BraTS-Toolkit)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = \"BraTS-GLI-00001-000\"\n",
    "data_path = Path(BASE_PATH) / \"data\"\n",
    "subject_path = data_path / subject\n",
    "utils.visualize_data(data_path, subject_id=subject)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using BraTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimal example using default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter = AdultGliomaSegmenter()\n",
    "segmenter.infer_single(\n",
    "    t1c=subject_path / f\"{subject}-t1c.nii.gz\",\n",
    "    t1n=subject_path / f\"{subject}-t1n.nii.gz\",\n",
    "    t2f=subject_path / f\"{subject}-t2f.nii.gz\",\n",
    "    t2w=subject_path / f\"{subject}-t2w.nii.gz\",\n",
    "    output_file=\"segmentation.nii.gz\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize results\n",
    "\n",
    "The segementation comprise of the\n",
    "TODO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.visualize_segmentation(\n",
    "    modality_file=subject_path / f\"{subject}-t1c.nii.gz\",\n",
    "    segmentation_file=\"segmentation.nii.gz\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch processing\n",
    "\n",
    "BraTS allows to run an algorithm for a single set of input images (t1n, t1c, t2f, t2w of the same patient) or for multiple subjects.\n",
    "Each of the available classes provides methods for both: \n",
    "- `.infer_single(...)` that takes in the paths to the required input modalities and a path to store the result\n",
    "- `.infer_batch(...)` that takes in a path to a data folder containing multiple sets of subjects and a path to an output folder to store the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The example below shows how to perform a batch inference\n",
    "The sets of subject inputs need to be stored in a specific structure to be recognized by the package:\n",
    "```\n",
    "data_folder\n",
    "┣ A\n",
    "┃ ┣ A-t1c.nii.gz\n",
    "┃ ┣ A-t1n.nii.gz\n",
    "┃ ┣ A-t2f.nii.gz\n",
    "┃ ┗ A-t2w.nii.gz\n",
    "┣ B\n",
    "┃ ┣ B-t1c.nii.gz\n",
    "┃ ┣ ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "output_path = Path(\"outputs\")\n",
    "\n",
    "segmenter = AdultGliomaSegmenter(cuda_devices=\"4\")\n",
    "segmenter.infer_batch(\n",
    "    data_folder=data_path,\n",
    "    output_folder=output_path,\n",
    ")\n",
    "\n",
    "print([path.name for path in output_path.iterdir()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default the algorithm that won the most recent challenge will be run on the first available GPU. This behavior and other options can be adapted, e.g.:\n",
    "- Select a different algorithm from the available constants (Enum classes for each challenge) with the `algorithm` parameter\n",
    "- Select a specific GPU if multiple are available with the `cuda_decives` parameter\n",
    "- Force CPU execution with the `force_cpu`flag (will cause an exception for many algorithms since many do not support CPU execution)\n",
    "- Save the generated logs in a log file with the `log_file` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter = AdultGliomaSegmenter(\n",
    "    algorithm=AdultGliomaAlgorithms.BraTS23_3, # Use the 3rd placed algorithm of the Adult Glioma BraTS 2023 challenge\n",
    "    cuda_devices=\"4\", # Select GPU device with ID 4\n",
    "    force_cpu=False, # default, could be set to True to force CPU\n",
    ")\n",
    "\n",
    "segmenter.infer_single(\n",
    "    t1c=subject_path / f\"{subject}-t1c.nii.gz\",\n",
    "    t1n=subject_path / f\"{subject}-t1n.nii.gz\",\n",
    "    t2f=subject_path / f\"{subject}-t2f.nii.gz\",\n",
    "    t2w=subject_path / f\"{subject}-t2w.nii.gz\",\n",
    "    output_file=\"segmentation.nii.gz\",\n",
    "    log_file=\"segmentation.log\", # Save the logs in a new filed called `segmentation.log`\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms from other Challenges\n",
    "\n",
    "BraTS provides the algorithms from all available recent BraTS Challenges, i.e.:\n",
    "- Adult Glioma Segmentation\n",
    "- BraTS-Africa Segmentation\n",
    "- Meningioma Segmentation\n",
    "- Brain Metastases Segmentation\n",
    "- Pediatric Tumors Segmentation\n",
    "- Inpainting\n",
    "\n",
    "The package provides a separate class and algorithm constants for each of the challenges.<br>\n",
    "The examples above were demonstrated using the class and constants of the Adult Glioma Segmentation challenge.\n",
    "\n",
    "In an identical way you can use:\n",
    "- `MeningiomaSegmenter` class with `MeningiomaAlgorithms`\n",
    "- `PediatricSegmenter` class with `PediatricAlgorithms`\n",
    "- etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.g. for the Meningioma Algorithms\n",
    "from brats import MeningiomaSegmenter\n",
    "from brats.constants import MeningiomaAlgorithms\n",
    "\n",
    "segmenter = MeningiomaSegmenter(\n",
    "    algorithm=MeningiomaAlgorithms.BraTS23_2, cuda_devices=\"4\"\n",
    ")\n",
    "segmenter.infer_batch(\n",
    "    data_folder=data_path, output_folder=output_path, log_file=\"test.log\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
